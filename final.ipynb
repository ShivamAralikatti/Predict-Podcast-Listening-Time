{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904a8737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3017241\ttest: 0.3018072\tbest: 0.3018072 (0)\ttotal: 104ms\tremaining: 1m 43s\n",
      "100:\tlearn: 0.1322671\ttest: 0.1314672\tbest: 0.1314672 (100)\ttotal: 2.81s\tremaining: 25s\n",
      "200:\tlearn: 0.1314686\ttest: 0.1306866\tbest: 0.1306866 (200)\ttotal: 5.47s\tremaining: 21.7s\n",
      "300:\tlearn: 0.1311230\ttest: 0.1304155\tbest: 0.1304155 (300)\ttotal: 7.96s\tremaining: 18.5s\n",
      "400:\tlearn: 0.1309206\ttest: 0.1302665\tbest: 0.1302665 (400)\ttotal: 10.4s\tremaining: 15.5s\n",
      "500:\tlearn: 0.1307143\ttest: 0.1301229\tbest: 0.1301229 (500)\ttotal: 12.8s\tremaining: 12.7s\n",
      "600:\tlearn: 0.1305719\ttest: 0.1300248\tbest: 0.1300248 (600)\ttotal: 15.2s\tremaining: 10.1s\n",
      "700:\tlearn: 0.1304595\ttest: 0.1299528\tbest: 0.1299528 (697)\ttotal: 17.7s\tremaining: 7.54s\n",
      "800:\tlearn: 0.1304024\ttest: 0.1299202\tbest: 0.1299200 (799)\ttotal: 20.1s\tremaining: 4.98s\n",
      "900:\tlearn: 0.1303063\ttest: 0.1298593\tbest: 0.1298591 (899)\ttotal: 22.5s\tremaining: 2.47s\n",
      "999:\tlearn: 0.1301999\ttest: 0.1297890\tbest: 0.1297890 (999)\ttotal: 24.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1297890481\n",
      "bestIteration = 999\n",
      "\n",
      "ðŸŒŸ CatBoost Quantile | RMSE: 13.19 | MAE: 9.52\n",
      "âœ… Saved submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===== LOAD DATA =====\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df  = pd.read_csv(\"test.csv\")\n",
    "test_df[\"Listening_Time_minutes\"] = np.nan\n",
    "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# ===== CREATE NEW FEATURES =====\n",
    "def enrich_features(df):\n",
    "    # Temporal (assuming a datetime column exists â€” else skip)\n",
    "    if 'Release_Date' in df.columns:\n",
    "        df['Release_Date'] = pd.to_datetime(df['Release_Date'])\n",
    "        df['Release_Weekday'] = df['Release_Date'].dt.weekday\n",
    "        df['Is_Weekend'] = df['Release_Weekday'] >= 5\n",
    "        df['Release_Hour'] = df['Release_Date'].dt.hour\n",
    "        df['Hour_Bucket'] = pd.cut(df['Release_Hour'], bins=[-1, 6, 12, 18, 24], labels=['Night', 'Morning', 'Afternoon', 'Evening'])\n",
    "    else:\n",
    "        df['Is_Weekend'] = 0\n",
    "        df['Hour_Bucket'] = 'Unknown'\n",
    "\n",
    "    # Interaction and ratios\n",
    "    df['Ad_Density'] = df['Number_of_Ads'] / (df['Episode_Length_minutes'] + 1e-3)\n",
    "    df['HostGuest_Mult'] = df['Host_Popularity_percentage'] * df['Guest_Popularity_percentage']\n",
    "    return df\n",
    "\n",
    "full_df = enrich_features(full_df)\n",
    "\n",
    "# ===== FEATURE ENCODING =====\n",
    "categorical_cols = ['Hour_Bucket']\n",
    "full_df[categorical_cols] = full_df[categorical_cols].astype(str)\n",
    "\n",
    "# ===== FEATURES TO USE =====\n",
    "features = [\n",
    "    'Episode_Length_minutes',\n",
    "    'Host_Popularity_percentage',\n",
    "    'Guest_Popularity_percentage',\n",
    "    'Number_of_Ads',\n",
    "    'Ad_Density',\n",
    "    'HostGuest_Mult',\n",
    "    'Is_Weekend',\n",
    "    'Hour_Bucket'\n",
    "]\n",
    "\n",
    "# ===== FILL MISSING =====\n",
    "for col in features:\n",
    "    if full_df[col].dtype == 'object':\n",
    "        full_df[col] = full_df[col].fillna('Unknown')\n",
    "    else:\n",
    "        full_df[col] = full_df[col].fillna(full_df[col].mean())\n",
    "\n",
    "# ===== SPLIT =====\n",
    "train_proc = full_df[~full_df['Listening_Time_minutes'].isna()]\n",
    "test_proc  = full_df[ full_df['Listening_Time_minutes'].isna()]\n",
    "\n",
    "X = train_proc[features]\n",
    "y = train_proc['Listening_Time_minutes'].astype(float)\n",
    "X_test = test_proc[features]\n",
    "test_ids = test_proc['id']\n",
    "\n",
    "# ===== LOG TRANSFORM TARGET =====\n",
    "y_log = np.log1p(y)  # log(1 + y) to handle 0s\n",
    "\n",
    "# ===== SPLIT TRAIN/VAL =====\n",
    "X_train, X_val, y_train_log, y_val_log = train_test_split(\n",
    "    X, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_pool = Pool(X_train, y_train_log, cat_features=categorical_cols)\n",
    "val_pool   = Pool(X_val, y_val_log, cat_features=categorical_cols)\n",
    "\n",
    "# ===== CATBOOST: QUANTILE LOSS =====\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='Quantile:alpha=0.5',  # Median regression\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "model.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "# ===== VALIDATION METRICS (inverse log) =====\n",
    "val_preds_log = model.predict(X_val)\n",
    "val_preds = np.expm1(val_preds_log)  # inverse of log1p\n",
    "\n",
    "y_val_true = np.expm1(y_val_log)\n",
    "rmse = mean_squared_error(y_val_true, val_preds, squared=False)\n",
    "mae  = mean_absolute_error(y_val_true, val_preds)\n",
    "\n",
    "print(f\"ðŸŒŸ CatBoost Quantile | RMSE: {rmse:.2f} | MAE: {mae:.2f}\")\n",
    "\n",
    "# ===== RETRAIN ON FULL DATA =====\n",
    "full_pool = Pool(X, y_log, cat_features=categorical_cols)\n",
    "model.fit(full_pool, verbose=0)\n",
    "\n",
    "# ===== PREDICT TEST SET =====\n",
    "test_preds_log = model.predict(X_test)\n",
    "test_preds = np.expm1(test_preds_log)\n",
    "\n",
    "# ===== SAVE PREDICTIONS =====\n",
    "pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Listening_Time_minutes': test_preds\n",
    "}).to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320ee9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 10.8645389\ttest: 10.8618389\tbest: 10.8618389 (0)\ttotal: 67.9ms\tremaining: 1m 7s\n",
      "100:\tlearn: 4.8190445\ttest: 4.8009239\tbest: 4.8009239 (100)\ttotal: 2.99s\tremaining: 26.6s\n",
      "200:\tlearn: 4.7937773\ttest: 4.7783754\tbest: 4.7783754 (200)\ttotal: 5.73s\tremaining: 22.8s\n",
      "300:\tlearn: 4.7805808\ttest: 4.7681149\tbest: 4.7681149 (300)\ttotal: 8.53s\tremaining: 19.8s\n",
      "400:\tlearn: 4.7688199\ttest: 4.7589815\tbest: 4.7589815 (400)\ttotal: 11.2s\tremaining: 16.7s\n",
      "500:\tlearn: 4.7588773\ttest: 4.7515607\tbest: 4.7515607 (500)\ttotal: 13.8s\tremaining: 13.7s\n",
      "600:\tlearn: 4.7516191\ttest: 4.7469805\tbest: 4.7469805 (600)\ttotal: 16.4s\tremaining: 10.9s\n",
      "700:\tlearn: 4.7451453\ttest: 4.7431704\tbest: 4.7431704 (700)\ttotal: 19.1s\tremaining: 8.13s\n",
      "800:\tlearn: 4.7391308\ttest: 4.7401318\tbest: 4.7401318 (800)\ttotal: 21.7s\tremaining: 5.39s\n",
      "900:\tlearn: 4.7334524\ttest: 4.7370737\tbest: 4.7370737 (900)\ttotal: 24.3s\tremaining: 2.67s\n",
      "999:\tlearn: 4.7281489\ttest: 4.7341173\tbest: 4.7341173 (999)\ttotal: 26.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 4.73411733\n",
      "bestIteration = 999\n",
      "\n",
      "Hybrid CatBoost RMSE: 13.12\n",
      "Hybrid CatBoost MAE : 9.47\n",
      "âœ… submission_hybrid_catboost.csv saved.\n"
     ]
    }
   ],
   "source": [
    "# ====================== SETUP ======================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ====================== LOAD DATA ======================\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df  = pd.read_csv(\"test.csv\")\n",
    "test_df[\"Listening_Time_minutes\"] = np.nan\n",
    "\n",
    "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# ====================== FEATURE ENGINEERING ======================\n",
    "numerical_features = [\n",
    "    \"Episode_Length_minutes\", \"Guest_Popularity_percentage\", \"Number_of_Ads\"\n",
    "]\n",
    "categorical_features = [\n",
    "    \"Podcast_Name\", \"Episode_Title\", \"Genre\", \"Publication_Day\", \n",
    "    \"Publication_Time\", \"Episode_Sentiment\"\n",
    "]\n",
    "\n",
    "# Impute\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "full_df[numerical_features] = num_imputer.fit_transform(full_df[numerical_features])\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "full_df[categorical_features] = cat_imputer.fit_transform(full_df[categorical_features])\n",
    "\n",
    "# ====================== AGGREGATED FEATURES ======================\n",
    "# Podcast-Level\n",
    "podcast_stats = full_df.groupby(\"Podcast_Name\").agg(\n",
    "    avg_listen=('Listening_Time_minutes', 'mean'),\n",
    "    std_listen=('Listening_Time_minutes', 'std'),\n",
    "    count_listen=('Listening_Time_minutes', 'count')\n",
    ").reset_index()\n",
    "full_df = full_df.merge(podcast_stats, on=\"Podcast_Name\", how=\"left\")\n",
    "\n",
    "# Genre-Level\n",
    "genre_stats = full_df.groupby(\"Genre\").agg(\n",
    "    genre_avg_listen=('Listening_Time_minutes', 'mean'),\n",
    "    genre_count=('Listening_Time_minutes', 'count')\n",
    ").reset_index()\n",
    "full_df = full_df.merge(genre_stats, on=\"Genre\", how=\"left\")\n",
    "\n",
    "# Day-Level\n",
    "day_stats = full_df.groupby(\"Publication_Day\").agg(\n",
    "    day_avg_listen=('Listening_Time_minutes', 'mean'),\n",
    ").reset_index()\n",
    "full_df = full_df.merge(day_stats, on=\"Publication_Day\", how=\"left\")\n",
    "\n",
    "# ====================== ENCODING ======================\n",
    "label_cols = [\"Podcast_Name\", \"Genre\", \"Publication_Day\", \"Publication_Time\", \"Episode_Sentiment\"]\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    full_df[col] = le.fit_transform(full_df[col])\n",
    "\n",
    "# ====================== FINAL FEATURES ======================\n",
    "drop_cols = [\"id\", \"Episode_Title\"]\n",
    "features = [col for col in full_df.columns if col not in drop_cols + [\"Listening_Time_minutes\"]]\n",
    "\n",
    "train_proc = full_df[~full_df[\"Listening_Time_minutes\"].isna()].copy()\n",
    "test_proc  = full_df[full_df[\"Listening_Time_minutes\"].isna()].copy()\n",
    "\n",
    "X = train_proc[features]\n",
    "y = train_proc[\"Listening_Time_minutes\"]\n",
    "X_test = test_proc[features]\n",
    "test_ids = test_proc[\"id\"]\n",
    "\n",
    "# ====================== TRAIN-VAL SPLIT ======================\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ====================== MODEL TRAINING ======================\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='Quantile:alpha=0.5',  # Robust to outliers\n",
    "    verbose=100,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "\n",
    "# ====================== EVALUATION ======================\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "val_preds = model.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, val_preds, squared=False)\n",
    "mae  = mean_absolute_error(y_val, val_preds)\n",
    "\n",
    "print(f\"Hybrid CatBoost RMSE: {rmse:.2f}\")\n",
    "print(f\"Hybrid CatBoost MAE : {mae:.2f}\")\n",
    "\n",
    "# ====================== FINAL PREDICTIONS ======================\n",
    "model.fit(X, y, verbose=0)\n",
    "final_preds = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"Listening_Time_minutes\": final_preds\n",
    "})\n",
    "submission.to_csv(\"submission_hybrid_catboost.csv\", index=False)\n",
    "print(\"âœ… submission_hybrid_catboost.csv saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f89b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
